# PoC Spark + Apache Iceberg (Bronze â†’ Silver)

Prova de conceito de um pipeline **Lakehouse** usando **Apache Spark** e **Apache Iceberg**, com ingestÃ£o simulada via Kafka, geraÃ§Ã£o de dados fake na camada Bronze, consolidaÃ§Ã£o genÃ©rica na camada Silver via `MERGE INTO` e validaÃ§Ã£o de consistÃªncia entre camadas.

O projeto roda **localmente via Docker** e estÃ¡ preparado para futura execuÃ§Ã£o em **OCI Data Flow**.

---

## ğŸ§± Stack

- Apache Spark 3.4.1
- Apache Iceberg 1.4.3
- Docker
- Python (PySpark)
- Arquitetura Bronze â†’ Silver
- MERGE ACID (Iceberg)

---

## ğŸ“ Estrutura do projeto

- **common/** â€“ Bibliotecas Python reutilizÃ¡veis
- **jobs/** â€“ Jobs Spark (consolidaÃ§Ã£o Silver e validaÃ§Ãµes)
- **scripts/** â€“ Geradores de dados fake (simulaÃ§Ã£o Kafka â†’ Bronze)
- **libs/** â€“ BinÃ¡rios do Spark e JARs do Iceberg
- **work/** â€“ Dados locais e warehouse Iceberg (nÃ£o versionado)
- **Dockerfile** â€“ Ambiente Spark local
- **entrypoint.sh** â€“ InicializaÃ§Ã£o do Spark
---
## ğŸ“¦ Download das dependÃªncias (obrigatÃ³rio)

Antes do build da imagem, faÃ§a o download dos binÃ¡rios necessÃ¡rios.

### Apache Spark 3.4.1

```bash
mkdir -p libs
cd libs

wget https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz

wget https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.4_2.12/1.4.3/iceberg-spark-runtime-3.4_2.12-1.4.3.jar
```
---
## ğŸ³ Build da imagem Docker
```
docker build --network=host -t poc-spark-delta:latest .
```
---
## â–¶ï¸ Executando o container local
```
docker run --rm -it \
  -v "$PWD/work":/work \
  -v "$PWD/common":/opt/app/common \
  -v "$PWD/jobs":/opt/app/jobs \
  -v "$PWD/scripts":/opt/app/scripts \
  poc-spark-delta:latest bash
```
---
## ğŸ” ValidaÃ§Ã£o do ambiente Spark
Dentro do container:
```
echo $SPARK_HOME                            # /opt/spark
which spark-submit                          # /opt/spark/bin/spark-submit
spark-submit --version                      # deve imprimir Spark 3.4.1
ls $SPARK_HOME/jars | grep iceberg          # iceberg-spark-runtime-3.4_2.12-1.4.3.jar
```
---
## ğŸ§ª GeraÃ§Ã£o de dados Bronze (entidade Ãºnica)
Simula mÃºltiplos tÃ³picos Kafka.
```
spark-submit scripts/gen_fake_schema_teste.py
```
---
## ğŸ§ª GeraÃ§Ã£o de dados Bronze (mÃºltiplas entidades)
```
spark-submit \
  scripts/gen_fake_bronze_multi_entities.py \
  --entities cliente,produto,pedido,fatura \
  --start-date 2026-01-01 \
  --end-date 2026-01-03 \
  --rows-per-day 1000 \
  --key-space 300
```
---
## ğŸ“¦ Gerando dependency archive (libs Python)
ObrigatÃ³rio para execuÃ§Ã£o distribuÃ­da do Spark.
```
cd /opt/app
rm /work/archive.zip
zip -r /work/archive.zip common -x "*/__pycache__/*"
```
---
## ğŸ”„ ConsolidaÃ§Ã£o Bronze â†’ Silver (Iceberg)
```
spark-submit \
  --py-files /work/archive.zip \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=/work/warehouse \
  jobs/poc_silver_iceberg_generic.py \
  --bronze-uri file:///work/bronze/schema_teste/tabela_teste \
  --catalog local \
  --database silver \
  --table tabela_teste \
  --pk idt_teste \
  --dedup-col dat_kafka \
  --partition-col dt_ref \
  --partition-range 2026-01-01,2026-01-03
```
---
## âœ… ValidaÃ§Ã£o Bronze vs Silver
Verifica:

  * contagem
  * cobertura de chaves
  * consistÃªncia de valores
```
spark-submit \
  --py-files /work/archive.zip \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=/work/warehouse \
  jobs/validate_bronze_vs_silver.py \
  --bronze-uri file:///work/bronze/schema_teste/tabela_teste \
  --catalog local \
  --database silver \
  --table tabela_teste \
  --pk idt_teste \
  --dedup-col dat_kafka \
  --partition-col dt_ref \
  --partition-range 2026-01-01,2026-01-03
```
---
## ğŸ§  ObservaÃ§Ãµes importantes

* O job Silver Ã© genÃ©rico (sem regra de negÃ³cio).
* O MERGE Ã© feito via Apache Iceberg (ACID).
* O mesmo cÃ³digo pode ser executado em OCI Data Flow sem alteraÃ§Ãµes.
* Todos os dados locais ficam em work/ (nÃ£o versionado).